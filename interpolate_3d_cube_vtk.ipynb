{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import scipy.io.idl as idl\n",
    "import numpy as np\n",
    "from scipy.interpolate import griddata\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.spatial import ConvexHull, Delaunay\n",
    "from scipy.interpolate import griddata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyvisfile.vtk import write_structured_grid\n",
    "from pytools.obj_array import make_obj_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "z_planes = [0.249, 0.302, 0.357, 0.416]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_idl(quantity, data_path='../../comprehensive_3d_plot/output/2016-04-07/'):\n",
    "    r\"\"\"\n",
    "    Read idl files for all planes.\n",
    "    \"\"\"\n",
    "    idl_ending = '.sav'\n",
    "    z249_file = data_path + quantity + '_z249' + idl_ending\n",
    "    z302_file = data_path + quantity + '_z302' + idl_ending\n",
    "    z357_file = data_path + quantity + '_z357' + idl_ending\n",
    "    z416_file = data_path + quantity + '_z416' + idl_ending\n",
    "    \n",
    "    z249_measurements = idl.readsav(z249_file)\n",
    "    z302_measurements = idl.readsav(z302_file)\n",
    "    z357_measurements = idl.readsav(z357_file)\n",
    "    z416_measurements = idl.readsav(z416_file)\n",
    "    \n",
    "    measurements = {0.249: z249_measurements, \n",
    "                    0.302: z302_measurements, \n",
    "                    0.357: z357_measurements, \n",
    "                    0.416: z416_measurements}\n",
    "\n",
    "    return measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_points_from_measurement_dict(measurement_dict, time_point, z_planes):\n",
    "    x_points = np.empty((0))\n",
    "    y_points = np.empty((0))\n",
    "    z_points = np.empty((0))\n",
    "    values = np.empty((0))\n",
    "    for z_plane in z_planes:\n",
    "        plane_measurements = measurement_dict[z_plane]\n",
    "        x_points = np.append(x_points, plane_measurements['x_out'])\n",
    "        y_points = np.append(y_points, plane_measurements['y_out'])\n",
    "        z_points = np.append(z_points, np.ones(plane_measurements['x_out'].size)*z_plane)\n",
    "        values = np.append(values, plane_measurements['a_out'][time_point])\n",
    "    \n",
    "    \n",
    "    points = [x_points, y_points, z_points]\n",
    "    points = np.asarray(points)\n",
    "    points = np.swapaxes(points, 0, 1)\n",
    "    return points, values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bounded_grid(bounds, spatial_increment=0.003):\n",
    "    \n",
    "    (x_min, x_max), (y_min, y_max), (z_min, z_max) = bounds\n",
    "    \n",
    "    x_coord = np.linspace(x_min, x_max, np.ceil((x_max-x_min)/spatial_increment))\n",
    "    y_coord = np.linspace(y_min, y_max, np.ceil((y_max-y_min)/spatial_increment))\n",
    "    z_coord = np.linspace(z_min, z_max, np.ceil((z_max-z_min)/spatial_increment))\n",
    "    \n",
    "    sizes = map(np.size, [x_coord, y_coord, z_coord])\n",
    "\n",
    "    mesh = np.meshgrid(x_coord, y_coord, z_coord, indexing='ij')\n",
    "    \n",
    "    grid_points = np.dstack(map(np.ravel, mesh))[0]\n",
    "    \n",
    "    return grid_points, sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def interpolate_vector(grid_points, vector_points, vector_values):\n",
    "    interpolated_data_x = griddata(vector_points[0], vector_values[0], grid_points)\n",
    "    interpolated_data_y = griddata(vector_points[1], vector_values[1], grid_points)\n",
    "    interpolated_data_z = griddata(vector_points[2], vector_values[2], grid_points)\n",
    "    return [interpolated_data_x, interpolated_data_y, interpolated_data_z]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def interpolate_scalar(grid_points, scalar_points, scalar_values):\n",
    "    interpolated_data = griddata(scalar_points, scalar_values, grid_points)\n",
    "    return interpolated_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_vacuum_field(field, vacuum_field=0.02):\n",
    "    field[2] = field[2] + vacuum_field\n",
    "    return field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepare_mesh(grid_points, sizes):\n",
    "    return grid_points.swapaxes(0,1).reshape((3, sizes[0], sizes[1], sizes[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepare_vector(vector, sizes):\n",
    "    vtk_vector_x = np.resize(vector[0], sizes)\n",
    "    vtk_vector_y = np.resize(vector[1], sizes)\n",
    "    vtk_vector_z = np.resize(vector[2], sizes)\n",
    "\n",
    "    vtk_vector_x = np.expand_dims(vtk_vector_x, 0)\n",
    "    vtk_vector_y = np.expand_dims(vtk_vector_y, 0)\n",
    "    vtk_vector_z = np.expand_dims(vtk_vector_z, 0)\n",
    "\n",
    "    vtk_vector = make_obj_array([vtk_vector_x, vtk_vector_y, vtk_vector_z])\n",
    "    return vtk_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepare_scalar(scalar, sizes):\n",
    "    vtk_scalar = np.resize(scalar, sizes)\n",
    "    vtk_scalar = np.expand_dims(scalar, 0)\n",
    "    return vtk_scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def average_duplicate_points(data_dict):\n",
    "    r\"\"\"\n",
    "    Find duplicate points, average them and record standard deviation.\n",
    "    \"\"\"\n",
    "    data_dict['x_out'] = data_dict['x_out'].astype('float64')\n",
    "    data_dict['y_out'] = data_dict['y_out'].astype('float64')\n",
    "    data_dict['a_out'] = data_dict['a_out'].astype('float64')\n",
    "    time_points = data_dict['a_out'].shape[0]\n",
    "    data = {}\n",
    "    for idx in xrange(data_dict['x_out'].size):\n",
    "        location = (data_dict['x_out'][idx], data_dict['y_out'][idx])\n",
    "        if location in data.keys():\n",
    "            data[location] = np.column_stack((data[location], data_dict['a_out'][:, idx]))\n",
    "        else:\n",
    "            data[location] = data_dict['a_out'][:, idx]\n",
    "\n",
    "    unique_data_dict = {'x_out': [],\n",
    "                        'y_out': [],\n",
    "                        'a_out': [],\n",
    "                        'std': []}\n",
    "    for location in data.keys():\n",
    "        if data[location][0].size > 1:\n",
    "            unique_data_dict['std'].append(data[location].std(axis=1, ddof=1))\n",
    "            unique_data_dict['a_out'].append(data[location].mean(axis=1))\n",
    "        else:\n",
    "            unique_data_dict['std'].append(np.zeros(time_points))\n",
    "            unique_data_dict['a_out'].append(data[location])\n",
    "        unique_data_dict['x_out'].append(location[0])\n",
    "        unique_data_dict['y_out'].append(location[1])\n",
    "\n",
    "    unique_data_dict['x_out'] = np.asarray(unique_data_dict['x_out'])\n",
    "    unique_data_dict['y_out'] = np.asarray(unique_data_dict['y_out'])\n",
    "    unique_data_dict['a_out'] = np.hsplit(np.asarray(unique_data_dict['a_out']), time_points)\n",
    "    unique_data_dict['delays'] = data_dict['delays']\n",
    "    return unique_data_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpolate B field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_min, x_max = -0.027, 0.022\n",
    "y_min, y_max = -0.021, 0.0295 \n",
    "z_min, z_max = 0.249, 0.416\n",
    "\n",
    "b_bounds = ((x_min, x_max), (y_min, y_max), (z_min, z_max)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bx_measurements = read_idl('bx')\n",
    "by_measurements = read_idl('by')\n",
    "bz_measurements = read_idl('bz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for plane in [0.249, 0.302, 0.357, 0.416]:\n",
    "    bx_measurements[plane] = average_duplicate_points(bx_measurements[plane])\n",
    "    by_measurements[plane] = average_duplicate_points(by_measurements[plane])\n",
    "    bz_measurements[plane] = average_duplicate_points(bz_measurements[plane])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "direction_measurements = [bx_measurements, by_measurements, bz_measurements] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "points = []\n",
    "values = []\n",
    "points_direction, values_direction = read_points_from_measurement_dict(bx_measurements, 0, [0.249])\n",
    "points.append(points_direction)\n",
    "values.append(values_direction)\n",
    "grid_points, sizes = bounded_grid(b_bounds, 0.003)\n",
    "interpolated_scalar = interpolate_scalar(grid_points, points[0], values[0])\n",
    "#interpolated_vector = add_vacuum_field(interpolated_vector)\n",
    "\n",
    "vtk_grid = prepare_mesh(grid_points, sizes)\n",
    "vtk_scalar = prepare_scalar(interpolated_scalar, sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=float64)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interpolated_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.027     , -0.021     ,  0.249     ],\n",
       "       [-0.027     , -0.021     ,  0.25203636],\n",
       "       [-0.027     , -0.021     ,  0.25507273],\n",
       "       ..., \n",
       "       [ 0.022     ,  0.0295    ,  0.40992727],\n",
       "       [ 0.022     ,  0.0295    ,  0.41296364],\n",
       "       [ 0.022     ,  0.0295    ,  0.416     ]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time_point 0\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-663975221aa4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minterpolated_vector\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minterpolated_vector\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minterpolated_vector\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for time_point in xrange(21):\n",
    "    print 'time_point %i' % time_point\n",
    "    points = []\n",
    "    values = []\n",
    "    for measurements in direction_measurements:\n",
    "        points_direction, values_direction = read_points_from_measurement_dict(measurements, time_point, z_planes)\n",
    "        points.append(points_direction)\n",
    "        values.append(values_direction)\n",
    "    grid_points, sizes = bounded_grid(b_bounds, 0.003)\n",
    "    interpolated_vector = interpolate_vector(grid_points, points, values)\n",
    "    interpolated_vector = add_vacuum_field(interpolated_vector)\n",
    "\n",
    "    assert np.sum(np.isnan(interpolated_vector[0])) == 0\n",
    "    assert np.sum(np.isnan(interpolated_vector[1])) == 0\n",
    "    assert np.sum(np.isnan(interpolated_vector[2])) == 0\n",
    "\n",
    "    \n",
    "    \n",
    "    vtk_grid = prepare_mesh(grid_points, sizes)\n",
    "    vtk_vector = prepare_vector(interpolated_vector, sizes)\n",
    "\n",
    "    output_path = '../output/2016-06-14/'\n",
    "    write_structured_grid(output_path + \n",
    "                          'b_' + str(time_point).zfill(4) + '.vts', vtk_grid, point_data=[('B', vtk_vector)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpolate Te & n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_min, x_max = -0.022, 0.018\n",
    "y_min, y_max = -0.021, 0.0255 \n",
    "z_min, z_max = 0.249, 0.416\n",
    "\n",
    "te_bounds = ((x_min, x_max), (y_min, y_max), (z_min, z_max)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "te_measurements = read_idl('te')\n",
    "n_measurements = read_idl('n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time_point 0\n",
      "time_point 0\n",
      "time_point 1\n",
      "time_point 1\n",
      "time_point 2\n",
      "time_point 2\n",
      "time_point 3\n",
      "time_point 3\n",
      "time_point 4\n",
      "time_point 4\n",
      "time_point 5\n",
      "time_point 5\n",
      "time_point 6\n",
      "time_point 6\n",
      "time_point 7\n",
      "time_point 7\n",
      "time_point 8\n",
      "time_point 8\n",
      "time_point 9\n",
      "time_point 9\n",
      "time_point 10\n",
      "time_point 10\n",
      "time_point 11\n",
      "time_point 11\n",
      "time_point 12\n",
      "time_point 12\n",
      "time_point 13\n",
      "time_point 13\n",
      "time_point 14\n",
      "time_point 14\n",
      "time_point 15\n",
      "time_point 15\n",
      "time_point 16\n",
      "time_point 16\n",
      "time_point 17\n",
      "time_point 17\n",
      "time_point 18\n",
      "time_point 18\n",
      "time_point 19\n",
      "time_point 19\n",
      "time_point 20\n",
      "time_point 20\n"
     ]
    }
   ],
   "source": [
    "for time_point in xrange(21):\n",
    "    print 'time_point %i' % time_point\n",
    "    te_points, te_values = read_points_from_measurement_dict(te_measurements, time_point, z_planes)\n",
    "    grid_points, sizes = bounded_grid(te_bounds, 0.003)\n",
    "    te_interpolated_scalar = interpolate_scalar(grid_points, te_points, te_values)\n",
    "    \n",
    "    assert np.sum(np.isnan(te_interpolated_scalar)) == 0\n",
    "    \n",
    "    vtk_grid = prepare_mesh(grid_points, sizes)\n",
    "    te_vtk_scalar = prepare_scalar(te_interpolated_scalar, sizes)\n",
    "    \n",
    "    \n",
    "    print 'time_point %i' % time_point\n",
    "    n_points, n_values = read_points_from_measurement_dict(n_measurements, time_point, z_planes)\n",
    "    n_interpolated_scalar = interpolate_scalar(grid_points, n_points, n_values)\n",
    "    \n",
    "    assert np.sum(np.isnan(n_interpolated_scalar)) == 0\n",
    "    \n",
    "    n_vtk_scalar = prepare_scalar(n_interpolated_scalar, sizes)\n",
    "    \n",
    "    \n",
    "    output_path = '../output/2016-06-14/'\n",
    "    write_structured_grid(output_path + \n",
    "                          'p_' + str(time_point).zfill(4) + '.vts', vtk_grid, point_data=[('Te', te_vtk_scalar),\n",
    "                                                                                          ('n', n_vtk_scalar)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
